{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_training.ipynb","provenance":[{"file_id":"1j9UWSZOCe0Gf96RH_wD5szB1DQ29B_RQ","timestamp":1623822019222},{"file_id":"1AoZVaXkULqikhtmJn1fgc4KgkyeOCicB","timestamp":1623753241785},{"file_id":"1i1SlXpg2bdjRSg4_UyuqHfmfUmqEY8wp","timestamp":1623650935705},{"file_id":"https://github.com/ratsgo/nlpbook/blob/master/examples/sentence_generation/train_colab.ipynb","timestamp":1623524899119}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8fcf1f43a69b4025bea9a1b2b57ea76c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2fe49270941048f987013b719c101942","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_550bad6c147a4bddb566a017e90e56df","IPY_MODEL_6b3dfb45d31a4c24b88eb5a18e83e46b"]}},"2fe49270941048f987013b719c101942":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"550bad6c147a4bddb566a017e90e56df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7665c122a068472ab4efa45381d31a59","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2825034,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2825034,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1acc6ae24b0241e68af21cb96df1dc9c"}},"6b3dfb45d31a4c24b88eb5a18e83e46b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_49437b7f4399493da5fe8f47cb14bb86","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.83M/2.83M [00:00&lt;00:00, 8.66MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2271561e6dd2468f839c5c16bc96bc0b"}},"7665c122a068472ab4efa45381d31a59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1acc6ae24b0241e68af21cb96df1dc9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49437b7f4399493da5fe8f47cb14bb86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2271561e6dd2468f839c5c16bc96bc0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b762778b86ef4669819c0acc7e024381":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e511f6fbe5ac4b9db903d1a608c7beb1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_39a1d26070be483e8985781bfca2f87e","IPY_MODEL_58ad0556583447ebae8e37983ce39782"]}},"e511f6fbe5ac4b9db903d1a608c7beb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39a1d26070be483e8985781bfca2f87e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e6701b3a200447b38f0ca17f58e33d3f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24095c0a9ea2431a83f81b8ed25fe429"}},"58ad0556583447ebae8e37983ce39782":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2aeb5b3a1e364f829c09facf6eb16a45","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.00k/1.00k [00:00&lt;00:00, 6.72kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f34246300afb4c33b12fa6fc5117cef0"}},"e6701b3a200447b38f0ca17f58e33d3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"24095c0a9ea2431a83f81b8ed25fe429":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2aeb5b3a1e364f829c09facf6eb16a45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f34246300afb4c33b12fa6fc5117cef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5170a9dfdf34caf8bf1074223284071":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e47bd1aaf396431cb1a3e9dbeb95c809","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_23afdb6975574b3a87d4fc7a3f9f343e","IPY_MODEL_da4fe48af6fe471ba01c31884b7f282e"]}},"e47bd1aaf396431cb1a3e9dbeb95c809":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23afdb6975574b3a87d4fc7a3f9f343e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0033ba3fda4848539a1575cedd37a3ce","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":513302779,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":513302779,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10e0be345e27463a8d5d6aa810e5ee67"}},"da4fe48af6fe471ba01c31884b7f282e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd971cf3da9a4febaa2d6e76f94cdc48","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 513M/513M [00:14&lt;00:00, 35.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a01f2b1c16a144d2afba310dd46912a6"}},"0033ba3fda4848539a1575cedd37a3ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"10e0be345e27463a8d5d6aa810e5ee67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd971cf3da9a4febaa2d6e76f94cdc48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a01f2b1c16a144d2afba310dd46912a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33c50641428a4692923be792d0d8cdfc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3e07633c052749a9b11d9a3a134ea807","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_43179395461e477babb52d48423189f7","IPY_MODEL_4a2a0b437dad4e7ca4b2b5cdde02d437"]}},"3e07633c052749a9b11d9a3a134ea807":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"43179395461e477babb52d48423189f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f15eb7733e894955b5f50b3bba42d256","_dom_classes":[],"description":"Epoch 0: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2455,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2455,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_083a3bcf69d242d992390022e7c5fb4d"}},"4a2a0b437dad4e7ca4b2b5cdde02d437":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2d18c5f44e7145519406dd12bbf5689b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2455/2455 [05:55&lt;00:00,  6.90it/s, loss=0.933, v_num=0, val_loss=0.949]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_118e85ef20354f56bf7af9d99b27f302"}},"f15eb7733e894955b5f50b3bba42d256":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"083a3bcf69d242d992390022e7c5fb4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d18c5f44e7145519406dd12bbf5689b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"118e85ef20354f56bf7af9d99b27f302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80fef021d5984b5d98ab80d0ce81f9f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_acce9cb6f20845769a9425fb87e93a09","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0bc48d2c7f0e469f9d20318a0a25ddd7","IPY_MODEL_853beb9d05d24c04b078ad58cd4bdd49"]}},"acce9cb6f20845769a9425fb87e93a09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"0bc48d2c7f0e469f9d20318a0a25ddd7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5ceb823e4cdc4851b79998e997056bf4","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":273,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":273,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cce109add4d14fc1a5b357f11d0f66e3"}},"853beb9d05d24c04b078ad58cd4bdd49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_34db7c5555d246aa9c08d976f2853f07","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 273/273 [00:12&lt;00:00, 23.00it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_caef27ade755483ebeb4008fdd8be2f9"}},"5ceb823e4cdc4851b79998e997056bf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cce109add4d14fc1a5b357f11d0f66e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34db7c5555d246aa9c08d976f2853f07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"caef27ade755483ebeb4008fdd8be2f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"y99F3zjbaEra"},"source":["# 1. 사전 준비"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbIy7HssH5_f","executionInfo":{"status":"ok","timestamp":1623823130722,"user_tz":-540,"elapsed":17587,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"facf45ca-f3e0-4de0-c337-4bfa8e3974f9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p36hSZiX6RNF"},"source":["### 패키지 설치하기\n","pip 명령어로 의존성 있는 패키지를 설치합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oP2CCSZiaZX8","executionInfo":{"status":"ok","timestamp":1623823149956,"user_tz":-540,"elapsed":367,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"547fe90e-a381-4de3-ca75-a71a85a20580"},"source":["%cd /content/drive/MyDrive/recipekogpt2/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/recipekogpt2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nlTGvFDPWw_","executionInfo":{"status":"ok","timestamp":1623819376250,"user_tz":-540,"elapsed":14845,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"93b71e77-7f5e-414c-d974-027d95897765"},"source":["!pip install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.8.1+cu101)\n","Collecting pytorch-lightning==1.3.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/3d/af3ea8cbd7c3cbb2b50d667062e70980ff56b50b835caf2c80e5da33a1ef/pytorch_lightning-1.3.4-py3-none-any.whl (806kB)\n","\u001b[K     |████████████████████████████████| 808kB 7.8MB/s \n","\u001b[?25hCollecting transformers==4.6.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 51.5MB/s \n","\u001b[?25hCollecting Korpora>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/b1/5e563e23f1f705574bbeb55555e0cb95c9813e9396d654cd42709418ab66/Korpora-0.2.0-py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.1.4)\n","Collecting flask_ngrok>=0.0.25\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Collecting flask_cors>=3.0.10\n","  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->-r requirements.txt (line 1)) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->-r requirements.txt (line 1)) (1.19.5)\n","Collecting tensorboard!=2.5.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 56.9MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (20.9)\n","Collecting future>=0.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 62.3MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/d2/d05466997f7751a2c06a7a416b7d1f131d765f7916698d3fdcb3a4d037e5/fsspec-2021.6.0-py3-none-any.whl (114kB)\n","\u001b[K     |████████████████████████████████| 122kB 63.5MB/s \n","\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 71.7MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.0\n","  Downloading https://files.pythonhosted.org/packages/14/52/aa227a0884df71ed1957649085adf2b8bc2a1816d037c2f18b3078854516/pyDeprecate-0.3.0-py3-none-any.whl\n","Collecting torchmetrics>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 70.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->-r requirements.txt (line 3)) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 41.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->-r requirements.txt (line 3)) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->-r requirements.txt (line 3)) (4.5.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 59.2MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Collecting xlrd>=1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/0c/c2a72d51fe56e08a08acc85d13013558a2d793028ae7385448a6ccdfae64/xlrd-2.0.1-py2.py3-none-any.whl (96kB)\n","\u001b[K     |████████████████████████████████| 102kB 12.5MB/s \n","\u001b[?25hCollecting dataclasses>=0.6\n","  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->-r requirements.txt (line 5)) (1.0.1)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->-r requirements.txt (line 5)) (2.11.3)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->-r requirements.txt (line 5)) (1.1.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->-r requirements.txt (line 5)) (7.1.2)\n","Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask_cors>=3.0.10->-r requirements.txt (line 7)) (1.15.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (1.34.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (0.36.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (1.31.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (3.12.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (0.12.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (0.4.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (57.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (2.4.7)\n","Collecting aiohttp; extra == \"http\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 63.6MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->-r requirements.txt (line 3)) (2021.5.30)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.1->-r requirements.txt (line 3)) (3.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 3)) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->-r requirements.txt (line 5)) (2.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (4.2.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (1.3.0)\n","Collecting multidict<7.0,>=4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n","\u001b[K     |████████████████████████████████| 143kB 70.9MB/s \n","\u001b[?25hCollecting async-timeout<4.0,>=3.0\n","  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n","Collecting yarl<2.0,>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n","\u001b[K     |████████████████████████████████| 296kB 66.0MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (21.2.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r requirements.txt (line 2)) (3.1.1)\n","Building wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=d2424af9b39e56d38ca0ed740226813c2ab6c24ff6456a08d5c26d925635df28\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","Successfully built future\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 2.4.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: korpora 0.2.0 has requirement tqdm>=4.46.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, future, multidict, async-timeout, yarl, aiohttp, fsspec, PyYAML, pyDeprecate, torchmetrics, pytorch-lightning, tokenizers, sacremoses, huggingface-hub, transformers, xlrd, dataclasses, Korpora, flask-ngrok, flask-cors\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: xlrd 1.1.0\n","    Uninstalling xlrd-1.1.0:\n","      Successfully uninstalled xlrd-1.1.0\n","Successfully installed Korpora-0.2.0 PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 fsspec-2021.6.0 future-0.18.2 huggingface-hub-0.0.8 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 sacremoses-0.0.45 tensorboard-2.4.1 tokenizers-0.10.3 torchmetrics-0.3.2 transformers-4.6.1 xlrd-2.0.1 yarl-1.6.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ML-ubp246uzI"},"source":["### 각종 설정\n","모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."]},{"cell_type":"code","metadata":{"id":"dtoPBSH4v31j"},"source":["import torch\n","from ratsnlp.nlpbook.generation import GenerationTrainArguments\n","args = GenerationTrainArguments(\n","    pretrained_model_name=\"skt/kogpt2-base-v2\",\n","    downstream_corpus_name=\"recipegpt\",\n","    downstream_corpus_root_dir='/content/drive/MyDrive/recipekogpt2/data',\n","    downstream_model_dir=\"/content/drive/MyDrive/recipekogpt2/model_checkpoints\",\n","    max_seq_length=120,\n","    batch_size= 8 if torch.cuda.is_available() else 4,\n","    learning_rate=5e-5,\n","    epochs=1,\n","    tpu_cores=0 if torch.cuda.is_available() else 8,\n","    seed=7,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48RjaTAr7D4M"},"source":["### 랜덤 시드 고정\n","학습 재현을 위해 랜덤 시드를 고정합니다."]},{"cell_type":"code","metadata":{"id":"HuacSUSd7JRf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623777351392,"user_tz":-540,"elapsed":265,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"465017de-253c-459f-b681-2de5a9b0fbe2"},"source":["from ratsnlp import nlpbook\n","nlpbook.set_seed(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["set seed: 7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FeTvf0bc9bbV"},"source":["### 로거 설정\n","메세지 출력 등을 위한 logger를 설정합니다."]},{"cell_type":"code","metadata":{"id":"251gdehZ9iPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623776056781,"user_tz":-540,"elapsed":14,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"4c34d042-7ecb-4df4-ddda-1db3b8a2b817"},"source":["nlpbook.set_logger(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:ratsnlp:Training/evaluation parameters GenerationTrainArguments(pretrained_model_name='skt/kogpt2-base-v2', downstream_task_name='sentence-generation', downstream_corpus_name='recipegpt', downstream_corpus_root_dir='/content/drive/MyDrive/encodded_data', downstream_model_dir='/content/drive/MyDrive/ratsgockpt', max_seq_length=200, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=1, batch_size=32, cpu_workers=4, fp16=False, tpu_cores=0)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2DnwLCKB7cRq"},"source":["### 토크나이저 준비\n","토큰화를 수행하는 토크나이저를 선언합니다. 이때, 데이터를 만들 때 사용했던 token의 리스트(unused0~unused5)도 토크나이저가 잘 인식할 수 있도록 추가해줍니다. 각 토큰은 순서대로 요리이름의 시작과 끝, 재료의 시작과 끝, 레시피 본문의 시작과 끝을 나타냅니다."]},{"cell_type":"code","metadata":{"id":"OlcoBivi7hIY","colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["8fcf1f43a69b4025bea9a1b2b57ea76c","2fe49270941048f987013b719c101942","550bad6c147a4bddb566a017e90e56df","6b3dfb45d31a4c24b88eb5a18e83e46b","7665c122a068472ab4efa45381d31a59","1acc6ae24b0241e68af21cb96df1dc9c","49437b7f4399493da5fe8f47cb14bb86","2271561e6dd2468f839c5c16bc96bc0b"]},"executionInfo":{"status":"ok","timestamp":1623819412080,"user_tz":-540,"elapsed":4672,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"2c83da20-aa97-4923-de37-09070dd89067"},"source":["tokens_list = ['<unused0>','<unused1>','<unused2>','<unused3>','<unused4>','<unused5>']\n","from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n","  pad_token='<pad>', mask_token='<mask>', additional_special_tokens = tokens_list) \n","tokenizer.encode(\"<unused0><unused1><unused99>김상병$\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fcf1f43a69b4025bea9a1b2b57ea76c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2825034.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[9, 10, 108, 23201, 7648, 379]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_SSzmlh0Lv5","executionInfo":{"status":"ok","timestamp":1623819428344,"user_tz":-540,"elapsed":255,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"bbf7f812-ddd8-4376-aa1f-1e975c6614f1"},"source":["tokenizer.tokenize('<unused0><unused1><unused99>김상병$')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<unused0>', '<unused1>', '<unused99>', '▁김상', '병', '$']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"V6ZF3CJCapd8"},"source":["모델이 51200차원의 임베딩으로 훈련되었기 때문에 혹시 사이즈가 맞지 않는다면 special token을 잘못 추가한 것이며, 추후 훈련할 때 CUDA error가 나타나기 때문에 수정해야 합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XC-Qyswd5sR","executionInfo":{"status":"ok","timestamp":1623779831109,"user_tz":-540,"elapsed":267,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"2d3c7246-a504-48c1-dead-74f6d830b4d9"},"source":["tokenizer.vocab_size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["51200"]},"metadata":{"tags":[]},"execution_count":120}]},{"cell_type":"markdown","metadata":{"id":"hZbLCM5e7i6g"},"source":["# 2. 학습데이터 구축\n","학습데이터를 만듭니다.\n","### training data 구축"]},{"cell_type":"code","metadata":{"id":"v9s8znA17ovP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623779857029,"user_tz":-540,"elapsed":9826,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"2210a3f8-91ab-4cb4-e075-02aeff27af2f"},"source":["from ratsnlp.nlpbook.generation import NsmcCorpus, GenerationDataset\n","from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n","corpus = NsmcCorpus()\n","train_dataset = GenerationDataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"train\",\n",")\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    sampler=RandomSampler(train_dataset, replacement=False),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:ratsnlp:Creating features from dataset file at /content/drive/MyDrive/encodded_data/recipegpt\n","INFO:ratsnlp:loading train data... LOOKING AT /content/drive/MyDrive/encodded_data/recipegpt/recipegpt_train.txt\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences [took 5.839 s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>누룽지 두부 계란죽 <unused1> <unused2>[$'$애$호$박$'$,$ $'$표$고$버$섯$'$,$ $'$당$근$ $누$룽$지$ $누$룽$지$'$,$ $'$순$두$부$'$,$ $'$달$걀$'$,$ $'$참$기$름$'$,$ $'$소$금$'$,$ $'$참$깨$'$,$ $'$흰$ $후$추$'$]$ <unused3> <unused4>깨끗이 씻어 손질한 애호박 당근과 기둥을 뗀 표고버섯을 잘게 다지듯이 썬다. 누룽지는 1 정도로 잘게 부숴준다. 냄비에 참기름을 두르고 썰어 놓은 채소를 볶다가 누룽지와 물을 넣고 끓인다. 누룽지가 살짝 퍼지면 순두부를 넣고 흰 후추와 소금을 넣는다. 죽이 끓으면 달걀을 풀어 넣고 한 소끔 끓여낸 후 참깨를 뿌려 마무리한다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁누 룽 지 ▁두부 ▁계 란 죽 ▁ <unused1> ▁ <unused2> ▁[ $ ' $ 애 $ 호 $ 박 $ ' $ , $ ▁ $ ' $ 표 $ 고 $ 버 $ 섯 $ ' $ , $ ▁ $ ' $ 당 $ 근 $ ▁ $ 누 $ 룽 $ 지 $ ▁ $ 누 $ 룽 $ 지 $ ' $ , $ ▁ $ ' $ 순 $ 두 $ 부 $ ' $ , $ ▁ $ ' $ 달 $ 걀 $ ' $ , $ ▁ $ ' $ 참 $ 기 $ 름 $ ' $ , $ ▁ $ ' $ 소 $ 금 $ ' $\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 9669, 7452, 8263, 44167, 9142, 7374, 8237, 739, 10, 739, 11, 9175, 379, 382, 379, 7982, 379, 8747, 379, 7597, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8669, 379, 6889, 379, 7621, 379, 7797, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7194, 379, 6949, 379, 739, 379, 7139, 379, 7452, 379, 8263, 379, 739, 379, 7139, 379, 7452, 379, 8263, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7849, 379, 7258, 379, 7669, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7187, 379, 6851, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8340, 379, 6958, 379, 7471, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7824, 379, 6953, 379, 382, 379], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 9669, 7452, 8263, 44167, 9142, 7374, 8237, 739, 10, 739, 11, 9175, 379, 382, 379, 7982, 379, 8747, 379, 7597, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8669, 379, 6889, 379, 7621, 379, 7797, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7194, 379, 6949, 379, 739, 379, 7139, 379, 7452, 379, 8263, 379, 739, 379, 7139, 379, 7452, 379, 8263, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7849, 379, 7258, 379, 7669, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7187, 379, 6851, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8340, 379, 6958, 379, 7471, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7824, 379, 6953, 379, 382, 379])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>오색지라시 스시 <unused1> <unused2>[$'$초$밥$밥$ $공$기$배$합$초$식$초$'$,$ $'$설$탕$'$,$ $'$소$금$ $오$색$지$라$시$달$걀$노$른$자$ $달$걀$'$,$ $'$표$고$버$섯$'$,$ $'$새$송$이$버$섯$'$,$ $'$새$우$ $마$리$'$,$ $'$홍$피$망$'$,$ $'$청$피$망$'$,$ $'$양$파$'$,$ $'$대$두$유$'$,$ $'$참$기$름$'$,$ $'$식$용$유$'$]$ <unused3> <unused4>배합초는 중불에서 설탕이 녹을 때까지 저어가면서 녹인다. 뜨거운 밥에 배합초를 넣어서 밥알이 으깨지지 않게 고루 저어가면서 밥을 체온 정도로 식힌다. 표고버섯은 기둥을 떼고 끓는 물에 데친 후 찬물에 헹궈 물기를 없애고 얇게 썰어 달궈진 팬에 참기름을 두르고 볶는다. 새송이버섯은 세로로 얇게 썰어 달궈진 팬에 참기름을 두르고 볶는다. 달걀 노른자를 고루  풀어 약한 불에 지단을 부친 후 채 썬다. 청피망과 홍피망은 채를 썬 후 달궈진 팬에 기름을 두르고 볶는다. 양파는 채를 썰어 찬물에 담가 매운맛을 제거한 뒤 달궈진 팬에 기름을 두르고 살짝 볶는다. 새우는 껍질을 벗기고 등 쪽 2-3 마디에 있는 내장을 꼬챙이로 꺼내고 물에 헹궈 물기를 뺀 다음 기름을 두르고 볶는다. 초밥 위에 청피망 홍피망 양파 달걀 노른자 새송이버섯 표고버섯 새우를 가지런히 놓는다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁오 색 지 라 시 ▁스 시 ▁ <unused1> ▁ <unused2> ▁[ $ ' $ 초 $ 밥 $ 밥 $ ▁ $ 공 $ 기 $ 배 $ 합 $ 초 $ 식 $ 초 $ ' $ , $ ▁ $ ' $ 설 $ 탕 $ ' $ , $ ▁ $ ' $ 소 $ 금 $ ▁ $ 오 $ 색 $ 지 $ 라 $ 시 $ 달 $ 걀 $ 노 $ 른 $ 자 $ ▁ $ 달 $ 걀 $ ' $ , $ ▁ $ ' $ 표 $ 고 $ 버 $ 섯 $ ' $ , $ ▁ $ ' $ 새 $ 송 $ 이 $\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 9114, 7770, 8263, 7372, 7888, 9230, 7888, 739, 10, 739, 11, 9175, 379, 382, 379, 8381, 379, 7605, 379, 7605, 379, 739, 379, 6900, 379, 6958, 379, 7609, 379, 8708, 379, 8381, 379, 7889, 379, 8381, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7793, 379, 8528, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7824, 379, 6953, 379, 739, 379, 8052, 379, 7770, 379, 8263, 379, 7372, 379, 7888, 379, 7187, 379, 6851, 379, 7119, 379, 7469, 379, 8159, 379, 739, 379, 7187, 379, 6851, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8669, 379, 6889, 379, 7621, 379, 7797, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7769, 379, 7832, 379, 8146, 379], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 9114, 7770, 8263, 7372, 7888, 9230, 7888, 739, 10, 739, 11, 9175, 379, 382, 379, 8381, 379, 7605, 379, 7605, 379, 739, 379, 6900, 379, 6958, 379, 7609, 379, 8708, 379, 8381, 379, 7889, 379, 8381, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7793, 379, 8528, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7824, 379, 6953, 379, 739, 379, 8052, 379, 7770, 379, 8263, 379, 7372, 379, 7888, 379, 7187, 379, 6851, 379, 7119, 379, 7469, 379, 8159, 379, 739, 379, 7187, 379, 6851, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8669, 379, 6889, 379, 7621, 379, 7797, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7769, 379, 7832, 379, 8146, 379])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>두부 곤약 나물 비빔밥 <unused1> <unused2>[$'$두$부$ $곤$약$잡$곡$밥$두$부$'$,$ $'$흰$쌀$'$,$ $'$현$미$쌀$'$,$ $'$찹$쌀$'$,$ $'$실$곤$약$ $나$물$콩$나$물$'$,$ $'$표$고$버$섯$'$,$ $'$애$호$박$'$,$ $'$고$사$리$ $줄$기$'$,$ $'$당$근$'$,$ $'$소$금$'$,$ $'$소$금$ $나$물$데$침$비$빔$고$추$장$ $소$스$초$고$추$장$'$,$ $'$플$레$인$요$거$트$'$,$ $'$참$기$름$ $곁$들$임$새$싹$'$]$ <unused3> <unused4>고사리는 상태에 따라 2-5시간 정도 불린 후 30분 정도 삶아 찬물에 헹구어 물기를 짠다. 콩나물은 다듬어서 끓는 물에 데친 후 건져 식힌다. 불린 표고버섯은 물기를 짜서 채를 썰고 당근 애호박은 길이 3 정도로 채를 썰어 끓는 소금물에 살짝 데쳐 찬물에 헹구어 물기를 짜서 준비한다. 흰 쌀 현미쌀 찹쌀을 깨끗하게 씻고 30분 이상 불려 쌀에 1.2배의  물을 붓고 곤 약을 넣어 밥을 짓는다. 그릇에 밥과 준비된 재료를 넣어 소금으로 간을 하여 고루 버무려 준다. 초고추장 플레인 요구르트와 참기름을 섞어 비빔 고추장 소스를 준비한다. 두부는 1.5×1.5× 3로 자르고 잠길 만큼의 물을 붓고 3-4분 정도 끓인 후 속을 파 내어 그 속에 버무린 밥을 올린다. 새싹채소를 올려 준 후 비빔 고추 장소 그를 곁들 여 준다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁두부 ▁곤 약 ▁나 물 ▁비 빔밥 ▁ <unused1> ▁ <unused2> ▁[ $ ' $ 두 $ 부 $ ▁ $ 곤 $ 약 $ 잡 $ 곡 $ 밥 $ 두 $ 부 $ ' $ , $ ▁ $ ' $ 흰 $ 쌀 $ ' $ , $ ▁ $ ' $ 현 $ 미 $ 쌀 $ ' $ , $ ▁ $ ' $ 찹 $ 쌀 $ ' $ , $ ▁ $ ' $ 실 $ 곤 $ 약 $ ▁ $ 나 $ 물 $ 콩 $ 나 $ 물 $ ' $ , $ ▁ $ ' $ 표 $ 고 $ 버 $ 섯 $ ' $ , $\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 44167, 11057, 7992, 9063, 7561, 9072, 43933, 739, 10, 739, 11, 9175, 379, 382, 379, 7258, 379, 7669, 379, 739, 379, 6891, 379, 7992, 379, 8165, 379, 6890, 379, 7605, 379, 7258, 379, 7669, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8807, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8739, 379, 7584, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8341, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7892, 379, 6891, 379, 7992, 379, 739, 379, 7055, 379, 7561, 379, 8474, 379, 7055, 379, 7561, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8669, 379, 6889, 379, 7621, 379, 7797, 379, 382, 379, 387, 379], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 44167, 11057, 7992, 9063, 7561, 9072, 43933, 739, 10, 739, 11, 9175, 379, 382, 379, 7258, 379, 7669, 379, 739, 379, 6891, 379, 7992, 379, 8165, 379, 6890, 379, 7605, 379, 7258, 379, 7669, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8807, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8739, 379, 7584, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8341, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7892, 379, 6891, 379, 7992, 379, 739, 379, 7055, 379, 7561, 379, 8474, 379, 7055, 379, 7561, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8669, 379, 6889, 379, 7621, 379, 7797, 379, 382, 379, 387, 379])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>저염 간장을 이용한 닭개장 비빔밥 <unused1> <unused2>[$'$흑$미$밥$쌀$'$,$ $'$검$은$ $쌀$ $닭$가$슴$살$ $삶$기$닭$가$슴$살$'$,$ $'$월$계$수$ $잎$'$,$ $'$후$추$ $나$물$숙$주$ $봉$지$'$,$ $'$토$란$대$'$,$ $'$'$,$ $'$고$사$리$ $줄$기$고$명$달$걀$'$,$ $'$대$파$'$,$ $'$들$기$름$'$,$ $'$실$고$추$'$,$ $'$소$금$들$깨$ $소$스$들$깨$가$루$'$,$ $'$고$추$기$름$'$,$ $'$꿀$'$,$ $'$저$염$간$장$'$]$ <unused3> <unused4>쌀은 30분 정도 불린 후 물을 1 하여 밥을 짓는다. 숙주는 끓는 소금물에 넣어 숨이 죽으면 찬물에 헹구어 물기를 뺀다. 고사리는 상태에 따라 2-5시간 정도 불린 후 30분 정도 삶아 찬물에 헹구어 물기를 짠다. 말린 토란대는 미지근한 물에 하루 정도 담갔다가 끓는 물에 넣어 끓이다가 물러지면 꺼내어 미지근한 물에 1-담가 아린 맛을 뺀다. 숙주 토 란대 고사리는 따로 들기름에 살짝 볶아 준다. 대파는 파채를 썰은 후 물에 담가 매운 맛을 제거한다. 달걀은 지단을 부치고 채를 썬다. 닭 가슴살은 손질을 하여 냄비에 잠길 정도로 물을 붓고 누린내 제거를 위해 월계수잎과 후추를 넣고 15-20분 정도 삶아 식혀서 고기의 결대로 찢는다. 들깨가루 고추기름 꿀 저염 간장을 함께 섞어 소스를 만든다. 그릇에 밥 을 담고 준비된 고명을 올린 후 소스를 곁들인다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁저 염 ▁간 장을 ▁이용한 ▁닭 개 장 ▁비 빔밥 ▁ <unused1> ▁ <unused2> ▁[ $ ' $ 흑 $ 미 $ 밥 $ 쌀 $ ' $ , $ ▁ $ ' $ 검 $ 은 $ ▁ $ 쌀 $ ▁ $ 닭 $ 가 $ 슴 $ 살 $ ▁ $ 삶 $ 기 $ 닭 $ 가 $ 슴 $ 살 $ ' $ , $ ▁ $ ' $ 월 $ 계 $ 수 $ ▁ $ 잎 $ ' $ , $ ▁ $ ' $ 후 $ 추 $ ▁ $ 나 $ 물 $ 숙 $ 주 $ ▁ $ 봉 $ 지 $ ' $ , $ ▁ $ '\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 9265, 8037, 9226, 9607, 12395, 17366, 6841, 8168, 9072, 43933, 739, 10, 739, 11, 9175, 379, 382, 379, 8796, 379, 7584, 379, 7605, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 6858, 379, 8135, 379, 739, 379, 7902, 379, 739, 379, 7188, 379, 6824, 379, 7883, 379, 7760, 379, 739, 379, 7762, 379, 6958, 379, 7188, 379, 6824, 379, 7883, 379, 7760, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8105, 379, 6886, 379, 7847, 379, 739, 379, 8158, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8772, 379, 8397, 379, 739, 379, 7055, 379, 7561, 379, 7848, 379, 8236, 379, 739, 379, 7660, 379, 8263, 379, 382, 379, 387, 379, 739, 379, 382], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 9265, 8037, 9226, 9607, 12395, 17366, 6841, 8168, 9072, 43933, 739, 10, 739, 11, 9175, 379, 382, 379, 8796, 379, 7584, 379, 7605, 379, 7902, 379, 382, 379, 387, 379, 739, 379, 382, 379, 6858, 379, 8135, 379, 739, 379, 7902, 379, 739, 379, 7188, 379, 6824, 379, 7883, 379, 7760, 379, 739, 379, 7762, 379, 6958, 379, 7188, 379, 6824, 379, 7883, 379, 7760, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8105, 379, 6886, 379, 7847, 379, 739, 379, 8158, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8772, 379, 8397, 379, 739, 379, 7055, 379, 7561, 379, 7848, 379, 8236, 379, 739, 379, 7660, 379, 8263, 379, 382, 379, 387, 379, 739, 379, 382])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>취나물 비빔밥 & 청국장 쌈장 <unused1> <unused2>[$'$취$나$물$밥$밥$ $공$기$'$,$ $'$다$진$ $쇠$고$기$'$,$ $'$취$나$물$ $줄$기$'$,$ $'$다$진$ $양$파$'$,$ $'$다$진$마$늘$'$,$ $'$간$장$'$,$ $'$매$실$즙$'$,$ $'$참$기$름$'$,$ $'$참$깨$'$,$ $'$소$금$ $청$국$장$쌈$장$청$국$장$'$,$ $'$된$장$'$,$ $'$콩$가$루$'$,$ $'$멸$치$가$루$'$,$ $'$쌀$뜨$물$'$,$ $'$다$진$ $양$파$'$,$ $'$다$진$ $호$박$'$,$ $'$다$진$ $당$근$'$,$ $'$다$진$ $표$고$버$섯$'$,$ $'$다$진$ $호$두$'$,$ $'$참$기$름$'$]$ <unused3> <unused4>끓는 소금물에 취나물을 데쳐 찬물에 헹구어 물기를 짜고 1.5 정도로 썰어 참기름과 참깨에 묻힌다. 쇠고기를 곱게 다지고 다진 양파와 마늘 간장 매실즙을 넣고 양념하여 달궈진 프라이팬에 볶는다. 준비된 밥에 넣고 잘 섞는다. 다진 표고버섯 양파 호박 당근 호두를 달군 프라이팬에 참기름을 넣고 모두 볶는다. 청국장 된장을 쌀뜨물에 잘 풀고 콩가루 멸치 가루 와 볶아 놓은 재료 넣고 한 소끔 끓인다. 취나물밥과 청국장 쌈장을 같이 곁들인다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁취 나물 ▁비 빔밥 ▁& ▁청 국장 ▁쌈 장 ▁ <unused1> ▁ <unused2> ▁[ $ ' $ 취 $ 나 $ 물 $ 밥 $ 밥 $ ▁ $ 공 $ 기 $ ' $ , $ ▁ $ ' $ 다 $ 진 $ ▁ $ 쇠 $ 고 $ 기 $ ' $ , $ ▁ $ ' $ 취 $ 나 $ 물 $ ▁ $ 줄 $ 기 $ ' $ , $ ▁ $ ' $ 다 $ 진 $ ▁ $ 양 $ 파 $ ' $ , $ ▁ $ ' $ 다 $ 진 $ 마 $ 늘 $ ' $ , $ ▁ $ ' $ 간 $ 장 $\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 9499, 20551, 9072, 43933, 38228, 9300, 29688, 48908, 8168, 739, 10, 739, 11, 9175, 379, 382, 379, 8408, 379, 7055, 379, 7561, 379, 7605, 379, 7605, 379, 739, 379, 6900, 379, 6958, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7182, 379, 8265, 379, 739, 379, 7837, 379, 6889, 379, 6958, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8408, 379, 7055, 379, 7561, 379, 739, 379, 8239, 379, 6958, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7182, 379, 8265, 379, 739, 379, 8000, 379, 8615, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7182, 379, 8265, 379, 7487, 379, 7163, 379, 382, 379, 387, 379, 739, 379, 382, 379, 6826, 379, 8168, 379], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 9499, 20551, 9072, 43933, 38228, 9300, 29688, 48908, 8168, 739, 10, 739, 11, 9175, 379, 382, 379, 8408, 379, 7055, 379, 7561, 379, 7605, 379, 7605, 379, 739, 379, 6900, 379, 6958, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7182, 379, 8265, 379, 739, 379, 7837, 379, 6889, 379, 6958, 379, 382, 379, 387, 379, 739, 379, 382, 379, 8408, 379, 7055, 379, 7561, 379, 739, 379, 8239, 379, 6958, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7182, 379, 8265, 379, 739, 379, 8000, 379, 8615, 379, 382, 379, 387, 379, 739, 379, 382, 379, 7182, 379, 8265, 379, 7487, 379, 7163, 379, 382, 379, 387, 379, 739, 379, 382, 379, 6826, 379, 8168, 379])\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/drive/MyDrive/encodded_data/recipegpt/cached_train_PreTrainedTokenizerFast_120_recipegpt_sentence-generation [took 2.434 s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"SOAACuBY7vem"},"source":["### validation data 구축\n","학습 중에 평가할 테스트 데이터를 구축합니다."]},{"cell_type":"code","metadata":{"id":"mcm1tgfq7y84","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623778918698,"user_tz":-540,"elapsed":1392,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"8eaffeed-3337-447e-a60d-0051551f57ef"},"source":["val_dataset = GenerationDataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"test\",\n",")\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=args.batch_size,\n","    sampler=SequentialSampler(val_dataset),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:ratsnlp:Creating features from dataset file at /content/drive/MyDrive/encodded_data/recipegpt\n","INFO:ratsnlp:loading test data... LOOKING AT /content/drive/MyDrive/encodded_data/recipegpt/recipegpt_test.txt\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences [took 0.851 s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>치커리샐러드와 올리브 마늘 소스 <unused1> <unused2>[$'$치$커$리$ $샐$러$드$치$커$리$ $줄$기$'$,$ $'$적$양$배$추$'$,$ $'$양$파$'$,$ $'$당$근$ $올$리$브$마$늘$ $드$레$싱$올$리$브$유$'$,$ $'$식$초$'$,$ $'$설$탕$'$,$ $'$마$늘$ $쪽$'$]$ <unused3> <unused4>마늘은 곱게 다진다. 올리브유 식초 설탕 다진 마늘을 섞어 거품기로 충분히 저어주 어 올리브 마늘 드레싱을 만든다. 치 커리는 싱싱하게 찬물에 담갔다가 물기를 뺀 후 한 입 크기로 자르고 적양배추 양파 당근은 곱게 채를 썬다. 접시에 준비한 치 커리 적 양배추 양파 당근을 담고 올리브 마늘 드레싱을 뿌린다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁치 커 리 샐 러 드와 ▁올리브 ▁마늘 ▁소 스 ▁ <unused1> ▁ <unused2> ▁[ $ ▁' $ ▁치 $ ▁커 $ ▁리 $ ▁ $ ▁샐 $ ▁러 $ ▁드 $ ▁치 $ ▁커 $ ▁리 $ ▁ $ ▁줄 $ ▁기 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁적 $ ▁양 $ ▁배 $ ▁추 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁양 $ ▁파 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁당 $ ▁근 $ ▁ $ ▁올 $ ▁리 $ ▁브 $ ▁마 $ ▁늘 $ ▁ $ ▁드\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 9407, 8446, 7478, 7772, 7397, 15832, 29645, 19216, 9077, 7877, 739, 10, 739, 11, 9175, 379, 9194, 379, 9407, 379, 10114, 379, 9664, 379, 739, 379, 35119, 379, 9981, 379, 9535, 379, 9407, 379, 10114, 379, 9664, 379, 739, 379, 9566, 379, 9032, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9211, 379, 9164, 379, 9208, 379, 9220, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9164, 379, 9203, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9162, 379, 9252, 379, 739, 379, 9456, 379, 9664, 379, 10016, 379, 9109, 379, 10061, 379, 739, 379, 9535], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 9407, 8446, 7478, 7772, 7397, 15832, 29645, 19216, 9077, 7877, 739, 10, 739, 11, 9175, 379, 9194, 379, 9407, 379, 10114, 379, 9664, 379, 739, 379, 35119, 379, 9981, 379, 9535, 379, 9407, 379, 10114, 379, 9664, 379, 739, 379, 9566, 379, 9032, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9211, 379, 9164, 379, 9208, 379, 9220, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9164, 379, 9203, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9162, 379, 9252, 379, 739, 379, 9456, 379, 9664, 379, 10016, 379, 9109, 379, 10061, 379, 739, 379, 9535])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>시금치 우유 소스와 그린매쉬드포테이토 <unused1> <unused2>[$'$그$린$매$쉬$드$포$테$이$토$감$자$'$,$ $'$시$금$치$우$유$ $소$스$'$,$ $'$아$몬$드$'$,$ $'$설$탕$'$,$ $'$크$랜$베$리$'$,$ $'$치$커$리$ $시$금$치$우$유$ $소$스$시$금$치$'$,$ $'$우$유$'$]$ <unused3> <unused4>시금치는 끓는 소금물에 데쳐 찬물에 헹구어 물기를 짜고 우유를 넣고 블렌더에 곱게 갈아 체에 거른다. 감자는 껍질을 벗기고 찜기에 넣어 센 불에서 20분 정도 삶다가 젓가락으로 찔러서 들어가면 약한 불로 줄여 뜸을 들인 후 꺼내서 으깬다. 아몬드는 잘게 다진다. 치 커리는 씻어서 물기를 빼고 곱게 다진다. 으깬 감자 다진 치 커리 시 금치 우유 소스 설탕을  넣고 골고루 섞어 준다. 접시에 감자 담고 아몬드와 크랜베리를 올리고 시금치 우유 소스를 곁들인다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁시 금치 ▁우유 ▁소 스와 ▁그린 매 쉬 드 포 테 이 토 ▁ <unused1> ▁ <unused2> ▁[ $ ▁' $ ▁그 $ ▁린 $ ▁매 $ ▁쉬 $ ▁드 $ ▁포 $ ▁테 $ ▁이 $ ▁토 $ ▁감 $ ▁자 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁시 $ ▁금 $ ▁치 $ ▁우 $ ▁유 $ ▁ $ ▁소 $ ▁스 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁아 $ ▁몬 $ ▁드 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁설 $ ▁탕 $ ▁' $ ▁, $ ▁ $\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 9039, 40774, 24561, 9077, 11556, 10964, 7501, 7865, 7281, 8658, 8548, 8146, 8563, 739, 10, 739, 11, 9175, 379, 9194, 379, 9022, 379, 23266, 379, 9215, 379, 12503, 379, 9535, 379, 9231, 379, 10349, 379, 9018, 379, 9319, 379, 9244, 379, 9042, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9039, 379, 9285, 379, 9407, 379, 9132, 379, 9055, 379, 739, 379, 9077, 379, 9230, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9050, 379, 15209, 379, 9535, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9160, 379, 14568, 379, 9194, 379, 11481, 379, 739, 379], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 9039, 40774, 24561, 9077, 11556, 10964, 7501, 7865, 7281, 8658, 8548, 8146, 8563, 739, 10, 739, 11, 9175, 379, 9194, 379, 9022, 379, 23266, 379, 9215, 379, 12503, 379, 9535, 379, 9231, 379, 10349, 379, 9018, 379, 9319, 379, 9244, 379, 9042, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9039, 379, 9285, 379, 9407, 379, 9132, 379, 9055, 379, 739, 379, 9077, 379, 9230, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9050, 379, 15209, 379, 9535, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9160, 379, 14568, 379, 9194, 379, 11481, 379, 739, 379])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>브로콜리 컬리플라워 샐러드와 두유 요거트 소스 <unused1> <unused2>[$'$브$로$콜$리$컬$리$플$라$워$ $샐$러$드$브$로$콜$리$ $송$이$'$,$ $'$컬$리$플$라$워$ $송$이$'$,$ $'$적$양$파$'$,$ $'$강$낭$콩$'$,$ $'$건$포$도$'$,$ $'$호$두$'$,$ $'$소$금$ $두$유$요$거$트$ $소$스$두$유$'$,$ $'$플$레$인$요$거$트$'$,$ $'$레$몬$즙$'$,$ $'$설$탕$'$]$ <unused3> <unused4>두유에 플레인 요구르트와 레몬즙 설탕을 넣고 잘 섞어 두유 요구르트 소스를 만든다. 강낭콩은 물에 불린 후 콩과 물을 12. 넣고 20-2 정도 무르게 삶아 건진다. 호두는 굵 게 다진다. 브로콜리와 콜리 플라워는 한 입 크기로 썰어 끓는 소금물에 살짝 데쳐 찬물에 헹궈 물기를 뺀다. 쩍 양파는 얇게 채를 썬다. 접시에 데친 브로콜리와 콜리 플라워 적 양파 건 포도 호두 강낭콩을 담고 두유 요구르트 소스를 곁들여 낸다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁브로 콜 리 ▁컬 리 플라 워 ▁샐 러 드와 ▁두 유 ▁요 거 트 ▁소 스 ▁ <unused1> ▁ <unused2> ▁[ $ ▁' $ ▁브 $ ▁로 $ ▁콜 $ ▁리 $ ▁컬 $ ▁리 $ ▁플 $ ▁라 $ ▁워 $ ▁ $ ▁샐 $ ▁러 $ ▁드 $ ▁브 $ ▁로 $ ▁콜 $ ▁리 $ ▁ $ ▁송 $ ▁이 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁컬 $ ▁리 $ ▁플 $ ▁라 $ ▁워 $ ▁ $ ▁송 $ ▁이 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁적 $\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 23865, 8470, 7478, 16368, 7478, 22887, 8102, 35119, 7397, 15832, 9174, 8125, 9242, 6853, 8599, 9077, 7877, 739, 10, 739, 11, 9175, 379, 9194, 379, 10016, 379, 9454, 379, 11707, 379, 9664, 379, 16368, 379, 9664, 379, 10308, 379, 9755, 379, 12062, 379, 739, 379, 35119, 379, 9981, 379, 9535, 379, 10016, 379, 9454, 379, 11707, 379, 9664, 379, 739, 379, 9697, 379, 9018, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 16368, 379, 9664, 379, 10308, 379, 9755, 379, 12062, 379, 739, 379, 9697, 379, 9018, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9211, 379], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 23865, 8470, 7478, 16368, 7478, 22887, 8102, 35119, 7397, 15832, 9174, 8125, 9242, 6853, 8599, 9077, 7877, 739, 10, 739, 11, 9175, 379, 9194, 379, 10016, 379, 9454, 379, 11707, 379, 9664, 379, 16368, 379, 9664, 379, 10308, 379, 9755, 379, 12062, 379, 739, 379, 35119, 379, 9981, 379, 9535, 379, 10016, 379, 9454, 379, 11707, 379, 9664, 379, 739, 379, 9697, 379, 9018, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 16368, 379, 9664, 379, 10308, 379, 9755, 379, 12062, 379, 739, 379, 9697, 379, 9018, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9211, 379])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>칠곡석류국수 <unused1> <unused2>[$'$소$면$'$,$ $'$저$염$소$금$'$,$ $'$식$초$ $소$스$석$류$식$잣$'$,$ $'$아$몬$드$'$,$ $'$해$바$라$기$씨$'$,$ $'$호$두$'$,$ $'$호$박$씨$'$,$ $'$오$이$'$]$ <unused3> <unused4>잣 아몬드 해바라기씨 호두 호박씨는 다진다. 끓는 물에 저염 소금과 식초를 넣은 후 소면을 삶은 후 체에 건져 물기를 뺀다. 석류는 물 600와 함께 믹서에 갈아 준 다음 체에 걸러 즙을 낸다. 준비된 그릇에 면을 담고 차갑게 식힌 석류즙을 붓는다. 견과류 채 썬 오이를 고 명으로 올려 완성한다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁칠곡 석 류 국 수 ▁ <unused1> ▁ <unused2> ▁[ $ ▁' $ ▁소 $ ▁면 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁저 $ ▁염 $ ▁소 $ ▁금 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁식 $ ▁초 $ ▁ $ ▁소 $ ▁스 $ ▁석 $ ▁류 $ ▁식 $ ▁잣 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁아 $ ▁몬 $ ▁드 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁해 $ ▁바 $ ▁라 $ ▁기 $ ▁씨 $ ▁' $ ▁, $ ▁ $ ▁' $\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 45339, 7789, 7461, 6920, 7847, 739, 10, 739, 11, 9175, 379, 9194, 379, 9077, 379, 9411, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9265, 379, 9923, 379, 9077, 379, 9285, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9376, 379, 9206, 379, 739, 379, 9077, 379, 9230, 379, 9425, 379, 20182, 379, 9376, 379, 23764, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9050, 379, 15209, 379, 9535, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9098, 379, 9117, 379, 9755, 379, 9032, 379, 10896, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 45339, 7789, 7461, 6920, 7847, 739, 10, 739, 11, 9175, 379, 9194, 379, 9077, 379, 9411, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9265, 379, 9923, 379, 9077, 379, 9285, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9376, 379, 9206, 379, 739, 379, 9077, 379, 9230, 379, 9425, 379, 20182, 379, 9376, 379, 23764, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9050, 379, 15209, 379, 9535, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9098, 379, 9117, 379, 9755, 379, 9032, 379, 10896, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: <unused0>월남쌈우동면 & 저염토마토소스 <unused1> <unused2>[$'$라$이$스$페$이$퍼$'$,$ $'$백$김$치$'$,$ $'$닭$ $가$슴$살$'$,$ $'$부$추$'$,$ $'$우$동$면$ $저$염$토$마$토$소$스$마$늘$'$,$ $'$사$과$'$,$ $'$양$파$'$,$ $'$레$드$와$인$'$,$ $'$토$마$토$'$,$ $'$핫$ $소$스$'$,$ $'$레$몬$즙$'$,$ $'$후$춧$가$루$'$]$ <unused3> <unused4>마늘 양파 사과 토마토는 다진다. 팬에 기름을 두르고 마늘 양파 사과 토마토 순으로 볶는다. 레드 와인 핫 소스 레몬즙을 넣어 반으로 졸인 후 후 춧가루를 넣어 소스를 완성한 다 가락국수 면은 삶은 후 체에 건져 물기를 뺀다. 백김치 부추는 3×1로 썬다. 닭 가슴살은 삶아 찢는다. 따뜻한 육수에 라이스페이퍼를 넣었다 꺼내어 가락국수 면 백김치 부추 닭 가슴 살을 넣고 말아준다. 토마토소스를 곁들인다. <unused5>\n","INFO:ratsnlp:tokens: <unused0> ▁월남 쌈 우 동면 ▁& ▁저 염 토마토 소스 ▁ <unused1> ▁ <unused2> ▁[ $ ▁' $ ▁라 $ ▁이 $ ▁스 $ ▁페 $ ▁이 $ ▁퍼 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁백 $ ▁김 $ ▁치 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁닭 $ ▁ $ ▁가 $ ▁ 슴 $ ▁살 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁부 $ ▁추 $ ▁' $ ▁, $ ▁ $ ▁' $ ▁우 $ ▁동 $ ▁면 $ ▁ $ ▁저 $ ▁염 $ ▁토 $ ▁마 $ ▁토\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[9, 28811, 7904, 8092, 31847, 38228, 9265, 8037, 45837, 22092, 739, 10, 739, 11, 9175, 379, 9194, 379, 9755, 379, 9018, 379, 9230, 379, 9942, 379, 9018, 379, 11061, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9358, 379, 9324, 379, 9407, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 17366, 379, 739, 379, 9028, 379, 739, 7883, 379, 9339, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9064, 379, 9220, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9132, 379, 9070, 379, 9411, 379, 739, 379, 9265, 379, 9923, 379, 9319, 379, 9109, 379, 9319], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[9, 28811, 7904, 8092, 31847, 38228, 9265, 8037, 45837, 22092, 739, 10, 739, 11, 9175, 379, 9194, 379, 9755, 379, 9018, 379, 9230, 379, 9942, 379, 9018, 379, 11061, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9358, 379, 9324, 379, 9407, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 17366, 379, 739, 379, 9028, 379, 739, 7883, 379, 9339, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9064, 379, 9220, 379, 9194, 379, 11481, 379, 739, 379, 9194, 379, 9132, 379, 9070, 379, 9411, 379, 739, 379, 9265, 379, 9923, 379, 9319, 379, 9109, 379, 9319])\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/drive/MyDrive/encodded_data/recipegpt/cached_test_PreTrainedTokenizerFast_100_recipegpt_sentence-generation [took 0.261 s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4LUggw0ibYym"},"source":["# 3. 학습 준비"]},{"cell_type":"markdown","metadata":{"id":"HztMCywb70e9"},"source":["### 모델 초기화\n","프리트레인이 완료된 GPT2 모델을 읽고, 문장 생성 모델을 초기화합니다."]},{"cell_type":"code","metadata":{"id":"staYwMx88MWQ","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["b762778b86ef4669819c0acc7e024381","e511f6fbe5ac4b9db903d1a608c7beb1","39a1d26070be483e8985781bfca2f87e","58ad0556583447ebae8e37983ce39782","e6701b3a200447b38f0ca17f58e33d3f","24095c0a9ea2431a83f81b8ed25fe429","2aeb5b3a1e364f829c09facf6eb16a45","f34246300afb4c33b12fa6fc5117cef0","c5170a9dfdf34caf8bf1074223284071","e47bd1aaf396431cb1a3e9dbeb95c809","23afdb6975574b3a87d4fc7a3f9f343e","da4fe48af6fe471ba01c31884b7f282e","0033ba3fda4848539a1575cedd37a3ce","10e0be345e27463a8d5d6aa810e5ee67","fd971cf3da9a4febaa2d6e76f94cdc48","a01f2b1c16a144d2afba310dd46912a6"]},"executionInfo":{"status":"ok","timestamp":1623776078656,"user_tz":-540,"elapsed":17363,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"f13b92e5-8b51-487d-d53d-d85869420c58"},"source":["from transformers import GPT2LMHeadModel\n","model = GPT2LMHeadModel.from_pretrained(\n","    args.pretrained_model_name\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b762778b86ef4669819c0acc7e024381","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1000.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5170a9dfdf34caf8bf1074223284071","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513302779.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lYtJXijM8PN8"},"source":["Task와 Trainer를 준비합니다."]},{"cell_type":"code","metadata":{"id":"OSS2D2PItanW"},"source":["train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    sampler=RandomSampler(train_dataset, replacement=False),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")\n","\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=args.batch_size,\n","    sampler=SequentialSampler(val_dataset),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FFn4MSz8SWu"},"source":["from ratsnlp.nlpbook.generation import GenerationTask\n","task = GenerationTask(model, args)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q5W0aktNbrSe"},"source":["traininer 선언 : checkpoint부터 이어서 학습한다면, file exists 경고가 뜨지만 args를 도중에 바꾸지 않는다면 문제는 없습니다."]},{"cell_type":"code","metadata":{"id":"18W4vRtR8UTx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623778952978,"user_tz":-540,"elapsed":239,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"476467af-4ded-44bf-8564-7676ae9e2601"},"source":["trainer = nlpbook.get_trainer(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"KteHdhBT8X0e"},"source":["# 4. 학습\n","준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/recipekogpt2/model_checkpoints`)에 저장됩니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtUszllmlBxq","executionInfo":{"status":"ok","timestamp":1623777808847,"user_tz":-540,"elapsed":239,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"258197ed-3311-4a71-81f1-e14c06558299"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tue Jun 15 17:23:28 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P0    41W / 250W |  16259MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SDr3M_nF8l7M","colab":{"base_uri":"https://localhost:8080/","height":236,"referenced_widgets":["33c50641428a4692923be792d0d8cdfc","3e07633c052749a9b11d9a3a134ea807","43179395461e477babb52d48423189f7","4a2a0b437dad4e7ca4b2b5cdde02d437","f15eb7733e894955b5f50b3bba42d256","083a3bcf69d242d992390022e7c5fb4d","2d18c5f44e7145519406dd12bbf5689b","118e85ef20354f56bf7af9d99b27f302","80fef021d5984b5d98ab80d0ce81f9f7","acce9cb6f20845769a9425fb87e93a09","0bc48d2c7f0e469f9d20318a0a25ddd7","853beb9d05d24c04b078ad58cd4bdd49","5ceb823e4cdc4851b79998e997056bf4","cce109add4d14fc1a5b357f11d0f66e3","34db7c5555d246aa9c08d976f2853f07","caef27ade755483ebeb4008fdd8be2f9"]},"executionInfo":{"status":"ok","timestamp":1623779313244,"user_tz":-540,"elapsed":356752,"user":{"displayName":"손수용","photoUrl":"","userId":"03750708798624184517"}},"outputId":"6b24e0ea-177d-4e95-a066-e3ba1ce180c9"},"source":["trainer.fit(\n","    task,\n","    train_dataloader=train_dataloader,\n","    val_dataloaders=val_dataloader,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type            | Params\n","------------------------------------------\n","0 | model | GPT2LMHeadModel | 125 M \n","------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33c50641428a4692923be792d0d8cdfc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80fef021d5984b5d98ab80d0ce81f9f7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]}]}